# -*- coding: utf-8 -*-
"""randomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DHEfUjrVloBMvU-r77P1bLp6wwX_a6C-
"""

#---------------------------------------------#
#-------| Written By: Sibt ul Hussain |-------#
#---------------------------------------------#


#---------------Instructions------------------#
# Please read the function documentation before
# proceeding with code writing. 

# For randomizing, you will need to use following functions
# please refer to their documentation for further help.
# 1. np.random.randint
# 2. np.random.random
# 3. np.random.shuffle
# 4. np.random.normal 


# Other Helpful functions: np.atleast_2d, np.squeeze()
# scipy.stats.mode, np.newaxis

#-----------------------------------------------#

# Now, go and look for the missing code sections and fill them.
#-------------------------------------------#
import tree as tree
import numpy as np
import scipy.stats as stats
import pandas as pd
np.random.seed(seed=99)

class RandomForest:
    ''' Implements the Random Forest For Classification... '''
    def __init__(self, ntrees=10,tpurity=0.95,treedepth=5,usebagging=False,baggingfraction=0.6,
        weaklearner="Conic",
        nsplits=10,        
        nfeattest=None, posteriorprob=False,scalefeat=True):        
        """      
            Build a random forest classification forest....

            Input:
            ---------------
                ntrees: number of trees in random forest
                treedepth: depth of each tree 
                usebagging: to use bagging for training multiple trees
                baggingfraction: what fraction of training set to use for building each tree,
                weaklearner: which weaklearner to use at each interal node, e.g. "Conic, Linear, Axis-Aligned, Axis-Aligned-Random",
                nsplits: number of splits to test during each feature selection round for finding best IG,                
                nfeattest: number of features to test for random Axis-Aligned weaklearner
                posteriorprob: return the posteriorprob class prob 
                scalefeat: wheter to scale features or not...
        """

        self.ntrees=ntrees
        self.treedepth=treedepth
        self.usebagging=usebagging
        self.baggingfraction=baggingfraction

        self.weaklearner=weaklearner
        self.nsplits=nsplits
        self.nfeattest=nfeattest
        self.tpurity = tpurity
        
        self.posteriorprob=posteriorprob
        
        self.scalefeat=scalefeat
        
        pass    
    def findScalingParameters(self,X):
        """
            find the scaling parameters
            input:
            -----------------
                X= m x d training data matrix...
        """
        self.mean=np.mean(X)
        self.std=np.std(X)
    def applyScaling(self,X):
        """
            Apply the scaling on the given training parameters
            Input:
            -----------------
                X: m x d training data matrix...
            Returns:
            -----------------
                X: scaled version of X
        """
        X= X - self.mean
        X= X /self.std
        return X
    def train(self,X,Y,vX=None,vY=None):
            '''
            Trains a RandomForest using the provided training set..
            
            Input:
            ---------
            X: a m x d matrix of training data...
            Y: labels (m x 1) label matrix

            vX: a n x d matrix of validation data (will be used to stop growing the RF)...
            vY: labels (n x 1) label matrix

            Returns:
            -----------

            '''

            nexamples, nfeatures= X.shape

            self.findScalingParameters(X)
            if self.scalefeat:
                X=self.applyScaling(X)

            self.trees=[]
            
            
            #-----------------------TODO-----------------------#
            #--------Write Your Code Here ---------------------#
            _Xtrain = X.copy()
            _Ytrain = Y.copy()
            for _ in range(self.ntrees):
                if self.usebagging:
                    a = np.array([i for i in range(len(_Ytrain))])
                    bs_idx = np.random.choice(a=a,size=int(nexamples*self.baggingfraction),replace=True,p =None)
                    t = tree.DecisionTree(weaklearner=self.weaklearner,maxdepth=self.treedepth,nsplits=self.nsplits, nfeattest=self.nfeattest,purity=self.tpurity)
                    t.train(_Xtrain[bs_idx],_Ytrain[bs_idx])
                    self.trees.append(t)
                else:
                    _nexamples = _Ytrain.shape[0]
                    a = np.array([i for i in range(len(_Ytrain))])
                    bs_idx = np.random.choice(a=a,size=int(_nexamples*self.baggingfraction),replace=True,p =None)
                    t = tree.DecisionTree(weaklearner=self.weaklearner,maxdepth=self.treedepth,nsplits=self.nsplits, nfeattest=self.nfeattest,purity=self.tpurity)
                    t.train(_Xtrain[bs_idx],_Ytrain[bs_idx])
                    self.trees.append(t)
                    res = t.test(X)
                    
                    addFraction = self.baggingfraction/2
                    for i in range(int(nexamples*addFraction)):
                        Xtrain = np.vstack((X,X[res!=Y]))
                        Ytrain = np.append(Y,Y[Y!=res])
                    


            #---------End of Your Code-------------------------#
        
    def predict(self, X):
        
        """
        Test the trained RF on the given set of examples X
        
                   
            Input:
            ------
                X: [1 x d] a d-dimensional test example.
           
            Returns:
            -----------
                pclass: the predicted class for the given example, i.e. to which it belongs
        """
        z=[]
        
        if self.scalefeat:
            X=self.applyScaling(X)

        #-----------------------TODO-----------------------#
        #--------Write Your Code Here ---------------------#
        
        res = [t.predict(X) for t in self.trees]
        return max(res)
        
        #---------End of Your Code-------------------------#


    def test(self,X):
        """
        Test the trained RF on the given set of examples X
        
                   
            Input:
            ------
                X: [m x d] a d-dimensional test example.
           
            Returns:
            -----------
                pclasses: the predicted class for the given example, i.e. to which it belongs
        """
        pclasses=[self.predict(e) for e in X]

        return pclasses